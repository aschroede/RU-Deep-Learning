{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning &mdash; Assignment 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ninth assignment for the 2024 Deep Learning course (NWI-IMC070) of the Radboud University."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "**Names:** Andrew Schroeder and Fynn Gerding\n",
    "\n",
    "**Group:** 17\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions:**\n",
    "* Fill in your names and the name of your group.\n",
    "* Answer the questions and complete the code where necessary.\n",
    "* Keep your answers brief, one or two sentences is usually enough.\n",
    "* Re-run the whole notebook before you submit your work.\n",
    "* Save the notebook as a PDF and submit that in Brightspace together with the `.ipynb` notebook file.\n",
    "* The easiest way to make a PDF of your notebook is via File > Print Preview and then use your browser's print option to print to PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "In this assignment you will\n",
    "\n",
    "1. Implement and train a generative adversarial network.\n",
    "2. Experiment with reverse gradient training.\n",
    "3. Implement a CycleGAN.\n",
    "4. Experiment with CycleGAN optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required software\n",
    "\n",
    "If you haven't done so already, you will need to install the following additional libraries:\n",
    "* `torch` and `torchvision` for PyTorch,\n",
    "* `PIL`, the python image library\n",
    "* `sklearn`\n",
    "\n",
    "All libraries can be installed with `pip install`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# render plots as png, not as svg\n",
    "# (svg is very slow with large scatterplots)\n",
    "%config InlineBackend.figure_formats = ['png']\n",
    "%matplotlib inline\n",
    "import csv\n",
    "import glob\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn.datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import torch\n",
    "import torch.autograd\n",
    "import torchvision\n",
    "import torchvision.transforms\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "# Fix the seed to make the solutions more reproducible\n",
    "torch.manual_seed(12345);\n",
    "\n",
    "# Use the GPU if available\n",
    "def detect_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "device = detect_device();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 Moon dataset\n",
    "\n",
    "The noisy moon dataset is a synthetic dataset with the following distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100000\n",
    "noisy_moons = sklearn.datasets.make_moons(n_samples=n_samples, noise=.1)\n",
    "noisy_moons[0][:, 0] -= np.mean(noisy_moons[0][:, 0])\n",
    "noisy_moons[0][:, 0] /= np.std(noisy_moons[0][:, 0])\n",
    "noisy_moons[0][:, 1] -= np.mean(noisy_moons[0][:, 1])\n",
    "noisy_moons[0][:, 1] /= np.std(noisy_moons[0][:, 1])\n",
    "plt.plot(noisy_moons[0][:, 0], noisy_moons[0][:, 1], '.', alpha=0.05);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) Run the following code to convert the data to a PyTorch dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moon_dataset = torch.utils.data.TensorDataset(torch.tensor(noisy_moons[0], dtype=torch.float32),\n",
    "                                              torch.tensor(noisy_moons[1], dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2 Generator\n",
    "\n",
    "We define a generator that generates samples from a learned distribution, based on a random noise input.\n",
    "\n",
    "The generator accepts 1D input vector with 100 elements and has to output a 1D vector with 2 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoonGenerator(torch.nn.Module):\n",
    "    def __init__(self, input_size=100, output_size=2):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size, 100),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(100, 100),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(100, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) Generate some samples from this generator before training and plot the resulting distribution.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = MoonGenerator()\n",
    "x = torch.rand((n_samples, 100)) * 2 - 1\n",
    "y = gen(x).detach().cpu().numpy()\n",
    "plt.plot(y[:, 0], y[:, 1], '.', alpha=0.05);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3 Untrainable dummy generator network\n",
    "\n",
    "For our experiments, we also define an untrainable dummy generator network that produces samples from a uniform distribution. We'll use this later to investigate what our discriminator learns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniformMoonGenerator(torch.nn.Module):\n",
    "    def __init__(self, input_size=100, output_size=2):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.dummy_param = torch.nn.Parameter(torch.tensor([0.]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.rand((x.shape[0], self.output_size),\n",
    "                          device=x.device, dtype=x.dtype) * 4 - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) Run the code to generate some samples from this generator and plot the resulting distribution.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = UniformMoonGenerator()\n",
    "x = torch.randn((n_samples, 100))\n",
    "y = gen(x).detach().cpu().numpy()\n",
    "plt.plot(y[:, 0], y[:, 1], '.', alpha=0.05);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4 Discriminator (1 point)\n",
    "\n",
    "To train the generator, we need a discriminator that takes the samples from the generator and samples from the real distribution. For real samples, the discriminator should predict 1, for fake samples it should predict 0.\n",
    "\n",
    "For stability, we will exclude the final sigmoid activation from the discriminator and use the [BCEWithLogitsLoss](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html) function during training.\n",
    "\n",
    "**(a) Inspect the code for the discriminator below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoonDiscriminator(torch.nn.Module):\n",
    "    def __init__(self, inputs=2, hiddens=1024):\n",
    "        super().__init__()\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(inputs, hiddens),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hiddens, hiddens),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hiddens, 1)\n",
    "        )\n",
    "        # Note: Although this is a binary classifier, we do not yet apply\n",
    "        #       a sigmoid activation here. Instead, we'll use the\n",
    "        #       BCEWithLogitsLoss later to compute sigmoid + BCE loss in\n",
    "        #       a numerically stable way.\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the value of the discriminator in our sample space to see what it is doing.\n",
    "\n",
    "**(b) Run the code to plot the output of an untrained discriminator:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_discriminator(discriminator, xmin=-2.5, xmax=2.5, steps=500, device=device):\n",
    "    x0, x1 = torch.meshgrid(torch.linspace(xmin, xmax, steps=steps),\n",
    "                            torch.linspace(xmin, xmax, steps=steps), indexing='ij')\n",
    "    x = torch.stack([x0.flatten(), x1.flatten()], axis=1).to(device)\n",
    "    y = discriminator(x)\n",
    "    y = torch.sigmoid(y).detach().cpu().numpy()\n",
    "    y = y.reshape(x0.shape)\n",
    "    plt.contourf(x0, x1, y)\n",
    "    plt.colorbar()\n",
    "\n",
    "disc = MoonDiscriminator().to(device)\n",
    "plot_discriminator(disc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) How should we expect this plot to look after training the discriminator for the moon dataset?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.5 Adversarial training loop (1 point)\n",
    "\n",
    "Now we have a generator and a discriminator, we can attempt to train the model. We will define a training function that implements the adversarial training procedure:\n",
    "\n",
    "For each minibatch of real samples:\n",
    "1. Generate a batch of fake samples;\n",
    "2. Compute the discriminator loss on the real and fake samples;\n",
    "3. Optimize the discriminator;\n",
    "4. Generate another batch of fake samples;\n",
    "5. Compute the generator loss on the fake samples;\n",
    "6. Update the generator.\n",
    "\n",
    "To monitor training, we'll print the discriminator and generator loss. We'll also monitor the accuracy of the discriminator (the percentage of correctly labeled real and fake samples) and the 'accuracy' of the generator (the percentage of fake samples incorrectly labeled as real by the discriminator).\n",
    "\n",
    "**(a) Complete the training loop below:<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_adversarial(generator, discriminator, data_loader, epochs=10,\n",
    "                      lr_gen=0.001, lr_disc=0.001, device=device):\n",
    "    gen_optimizer = torch.optim.Adam(generator.parameters(), lr=lr_gen)\n",
    "    disc_optimizer = torch.optim.Adam(discriminator.parameters(), lr=lr_disc)\n",
    "\n",
    "    bce_logits_loss = torch.nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_disc_loss = 0\n",
    "        epoch_gen_loss = 0\n",
    "        epoch_disc_acc = 0\n",
    "        epoch_gen_acc = 0\n",
    "        mb_count = 0\n",
    "\n",
    "        for x_real, _ in data_loader:\n",
    "            x_real = x_real.to(device)\n",
    "\n",
    "            ## 1. Discriminator\n",
    "            # generate noise for the generator\n",
    "            rand_for_gen = torch.rand((x_real.shape[0], generator.input_size),\n",
    "                                      device=x_real.device, dtype=x_real.dtype) * 2 - 1\n",
    "            # generate fake samples\n",
    "            x_fake = generator(rand_for_gen)\n",
    "\n",
    "            # run discriminator on real and fake samples\n",
    "            d_real = discriminator(x_real)\n",
    "            d_fake = discriminator(x_fake)\n",
    "\n",
    "            # compute discriminator loss\n",
    "            # - for real samples, the discriminator should predict 1\n",
    "            # - for fake samples, the discriminator should predict 0\n",
    "            disc_loss = (bce_logits_loss(d_real, torch.ones_like(d_real)) +\n",
    "                         bce_logits_loss(d_fake, torch.zeros_like(d_fake)))\n",
    "            disc_acc = (torch.mean((d_real > 0).to(torch.float)) +\n",
    "                        torch.mean((d_fake < 0).to(torch.float))) / 2\n",
    "\n",
    "            # update discriminator\n",
    "            disc_optimizer.zero_grad()\n",
    "            disc_loss.backward()\n",
    "            disc_optimizer.step()\n",
    "\n",
    "\n",
    "            ## 2. Generator\n",
    "            # generate another batch of fake samples\n",
    "            rand_for_gen = torch.rand((x_real.shape[0], generator.input_size),\n",
    "                                      device=x_real.device, dtype=x_real.dtype) * 2 - 1\n",
    "            x_fake = generator(rand_for_gen)\n",
    "\n",
    "            # compute generator loss\n",
    "            d_fake = discriminator(x_fake)\n",
    "            # TODO: compute the generator loss using d_fake and bce_logits_loss\n",
    "            #       and the appropriate target value (see the implementation for\n",
    "            #       the discriminator loss)\n",
    "            gen_loss = ...\n",
    "            # for the generator, we compute how many generated samples were given\n",
    "            # the label 'real' by the discriminator\n",
    "            gen_acc = torch.mean((d_fake > 0).to(torch.float))\n",
    "\n",
    "            # update generator\n",
    "            gen_optimizer.zero_grad()\n",
    "            gen_loss.backward()\n",
    "            gen_optimizer.step()\n",
    "\n",
    "            ## 3. Statistics\n",
    "            epoch_disc_loss += disc_loss.item()\n",
    "            epoch_gen_loss += gen_loss.item()\n",
    "            epoch_disc_acc += disc_acc.item()\n",
    "            epoch_gen_acc += gen_acc.item()\n",
    "            mb_count += 1\n",
    "\n",
    "        print('Epoch %d: disc_loss=%f gen_loss=%f  disc_acc=%f gen_acc=%f' %\n",
    "              (epoch, epoch_disc_loss / mb_count, epoch_gen_loss / mb_count,\n",
    "               epoch_disc_acc / mb_count, epoch_gen_acc / mb_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.6 Experiment: Train the discriminator only (1 point)\n",
    "\n",
    "First, we'll train the discriminator only, using the dummy generator to generate samples from a uniform distribution.\n",
    "\n",
    "**(a) Run the code to train the discriminator:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = UniformMoonGenerator().to(device)\n",
    "disc = MoonDiscriminator().to(device)\n",
    "\n",
    "loader = torch.utils.data.DataLoader(moon_dataset, batch_size=128)\n",
    "train_adversarial(gen, disc, loader, epochs=10, lr_gen=0.001, lr_disc=0.001, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Plot the discriminator output and inspect the result.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_discriminator(disc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Why does the discriminator not predict 1.00 inside the moons?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.7 Experiment: Train the generator and discriminator (8 points)\n",
    "\n",
    "We'll now train the model with the trainable generator.\n",
    "\n",
    "**(a) Train the generator and discriminator together:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = MoonGenerator().to(device)\n",
    "disc = MoonDiscriminator().to(device)\n",
    "\n",
    "loader = torch.utils.data.DataLoader(moon_dataset, batch_size=128)\n",
    "train_adversarial(gen, disc, loader, epochs=10, lr_gen=0.001, lr_disc=0.001, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Run the code below to plot the generated samples, the discriminator output, and the real samples.**\n",
    "\n",
    "**Note:** If you don't get a good results, try to run the model again. This model is quite sensitive to the random initialisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_generator(generator, n_samples=1000, device=device):\n",
    "    x = torch.rand((n_samples, 100)).to(device) * 2 - 1\n",
    "    y = generator(x).detach().cpu().numpy()\n",
    "    plt.plot(y[:, 0], y[:, 1], 'b.', alpha=0.2)\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_discriminator(disc)\n",
    "plot_generator(gen)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(noisy_moons[0][:, 0], noisy_moons[0][:, 1], 'r.', alpha=0.05)\n",
    "plot_generator(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Briefly discuss this result.<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the output of the new discriminator with the output of the discriminator trained without a generator.\n",
    "\n",
    "**(d) Are the discriminator outputs the same? Explain why this happens.<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e) Does the discriminator still reach a high accuracy? Why (not?)<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(f) How can we see if the model is working well based on the discriminator accuracy?<span style=\"float:right\"> (2 points)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(g) Compare the distribution learned by the generator with the real distribution. What are the main differences?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(h) Explain the differences you observed above: Why are the generated and real distributions different?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(i) How can you make the distributions more similar?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.8 Gradient reversal (5 point)\n",
    "\n",
    "As an alternative to training the discriminator and generator separately, we can also train the model with a gradient reversal layer that reverses the gradient coming from the discriminator:\n",
    "\n",
    "```\n",
    "Forward: generator -> discriminator.\n",
    "Backward: generator gradient <- gradient reversal <- discriminator gradient.\n",
    "```\n",
    "\n",
    "In PyTorch, we'll implement this as a function `revgrad(x)` that will reverse the gradient that passes through it. You can use it like this:\n",
    "```\n",
    "y = discriminator(revgrad(generator(x)))\n",
    "loss = loss_fn(y, target)\n",
    "loss.backward()\n",
    "```\n",
    "\n",
    "**(a) Complete the code to define the `revgrad` gradient reversal function:<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RevGrad(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        output = input\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # TODO: Compute the reverse of the gradient\n",
    "        grad_input = ...\n",
    "        return grad_input\n",
    "\n",
    "revgrad = RevGrad.apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training loop is now a bit simpler than before, because we do not have to compute the generator loss separately.\n",
    "\n",
    "**(b) Complete the new training function:<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_adversarial_revgrad(generator, discriminator, data_loader, epochs=10, lr=0.001, device=device):\n",
    "    parameters = list(generator.parameters()) + list(discriminator.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
    "\n",
    "    bce_logits_loss = torch.nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc_real = 0\n",
    "        epoch_acc_fake = 0\n",
    "        mb_count = 0\n",
    "\n",
    "        for x_real, _ in data_loader:\n",
    "            x_real = x_real.to(device)\n",
    "\n",
    "            # generate fake samples\n",
    "            rand_for_gen = torch.rand((x_real.shape[0], generator.input_size),\n",
    "                                      device=x_real.device, dtype=x_real.dtype) * 2 - 1\n",
    "            x_fake = generator(rand_for_gen)\n",
    "\n",
    "            # run discriminator on real and random samples,\n",
    "            # reverse the gradient for the generator\n",
    "            d_real = discriminator(x_real)\n",
    "            # TODO: compute the discriminator output like before,\n",
    "            #       but include the gradient reversal layer\n",
    "            d_fake = ...\n",
    "\n",
    "            # compute loss\n",
    "            loss_real = bce_logits_loss(d_real, torch.ones_like(d_real))\n",
    "            loss_fake = bce_logits_loss(d_fake, torch.zeros_like(d_fake))\n",
    "            loss = loss_real + loss_fake\n",
    "            \n",
    "            # compute discriminator accuracy\n",
    "            acc_real = torch.mean((d_real > 0).to(torch.float))\n",
    "            acc_fake = torch.mean((d_fake < 0).to(torch.float))\n",
    "\n",
    "            # update generator and discriminator\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # update statistics\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc_real += acc_real.item()\n",
    "            epoch_acc_fake += acc_fake.item()\n",
    "            mb_count += 1\n",
    "\n",
    "        print('Epoch %d: loss=%f  acc_real=%f acc_fake=%f' %\n",
    "              (epoch, epoch_loss / mb_count,\n",
    "               epoch_acc_real / mb_count, epoch_acc_fake / mb_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Train a generator and discriminator with the new training function:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = MoonGenerator().to(device)\n",
    "disc = MoonDiscriminator().to(device)\n",
    "\n",
    "loader = torch.utils.data.DataLoader(moon_dataset, batch_size=128)\n",
    "train_adversarial_revgrad(gen, disc, loader, epochs=10, lr=0.001, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) Plot and inspect the results:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_discriminator(disc)\n",
    "plot_generator(gen)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(noisy_moons[0][:, 0], noisy_moons[0][:, 1], 'r.', alpha=0.1)\n",
    "plot_generator(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e) Briefly discuss the result.<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(f) What are some advantages and disadvantages of the gradient reversal layer, compared with the previous two-step approach?<span style=\"float:right\"> (2 points)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.9 Emoji dataset\n",
    "\n",
    "For the second part of this assignment we will borrow an emoji dataset (and some ideas) from a course at the [University of Toronto](http://www.cs.toronto.edu/~rgrosse/courses/csc421_2019/).\n",
    "\n",
    "The dataset contains images of Apple-style and Windows-style emojis. You can [download the files](http://www.cs.toronto.edu/~jba/emojis.tar.gz) yourself or use the code below.\n",
    "\n",
    "**(a) Download the dataset and extract the files:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget -c http://www.cs.toronto.edu/~jba/emojis.tar.gz\n",
    "# !tar xzf emojis.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll resize the images to 32 by 32 pixels and normalize the RGB intensities to values between -1 and 1.\n",
    "\n",
    "**(b) Run the code to construct the datasets:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        img = PIL.Image.open(f)\n",
    "        return img.convert('RGBA').convert('RGB')\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((32, 32)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "d_windows = torchvision.datasets.ImageFolder('emojis/Windows/', transform, loader=image_loader)\n",
    "d_apple = torchvision.datasets.ImageFolder('emojis/Apple/', transform, loader=image_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Plot a few images to see the different styles:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_grid(d, idxs):\n",
    "    images = [d[idx][0] for idx in idxs]\n",
    "    grid = torchvision.utils.make_grid(images)\n",
    "    return grid.numpy().transpose(1, 2, 0) / 2 + 0.5\n",
    "\n",
    "# Depending on the PyTorch version, this code might print\n",
    "# a warning about transparency. This is not a problem.\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image_grid(d_windows, range(100, 140)))\n",
    "plt.title('Windows')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(image_grid(d_apple, range(400, 440)))\n",
    "plt.title('Apple')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.10 CycleGAN (2 points)\n",
    "\n",
    "We'll try to train a CycleGAN that can translate emojis between the Windows and Apple styles.\n",
    "\n",
    "This CycleGAN has the following components:\n",
    "* A generator that translates from Windows to Apple;\n",
    "* A generator that translates from Apple to Windows;\n",
    "* A discriminator that discriminates between real and fake emojis from the Windows distribution;\n",
    "* A discriminator that discriminates between real and fake emojis from the Apple distribution.\n",
    "\n",
    "### Generator\n",
    "\n",
    "First, we define the generator. We'll use the same generator architecture for both directions. Unlike before, the generator does not take random noise as input, but expects a 32 by 32 RGB image as input and returns a 32 by 32 RGB image as output.\n",
    "\n",
    "The generator has the following structure:\n",
    "```\n",
    "- Input: 32x32 pixels, 3 channels.\n",
    "- Two downsampling + convolution blocks:\n",
    "  kernel size = (5, 5), stride = 2, padding = ?,\n",
    "  from 3 -> 32 -> 64 channels.\n",
    "- One convolution block in the middle:\n",
    "  kernel size = (5, 5), stride = 1, padding = ?,\n",
    "  from 64 -> 64 channels.\n",
    "- Two upsampling + convolution blocks:\n",
    "  upsampling (scale factor 2) followed by convolution,\n",
    "  kernel size = (5, 5), stride = 1, padding = ?,\n",
    "  from 64 -> 32 -> 3 channels.\n",
    "- Output: 32x32 pixels, 3 channels.\n",
    "```\n",
    "\n",
    "Add batch normalization and ReLU activations after each convolution, except after the very last layer.\n",
    "\n",
    "The images have a [-1, +1] range, so the last output should use a tanh activation without BN.\n",
    "\n",
    "**(a) Complete the code below:<span style=\"float:right\"> (2 points)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGenerator(torch.nn.Module):\n",
    "    def __init__(self, input_size=100):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.net = torch.nn.Sequential(\n",
    "            # downsampling 32 -> 16 -> 8 pixels\n",
    "            # TODO: implement the downsampling part as described above\n",
    "\n",
    "            # no downsampling, no upsampling\n",
    "            torch.nn.Conv2d(64, 64, (5, 5), padding=2, bias=False),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            # upsampling 8 -> 16 -> 32 pixels\n",
    "            # TODO: complete the upsampling part as described above\n",
    "            \n",
    "            torch.nn.Upsample(scale_factor=2),\n",
    "            torch.nn.Conv2d(32, 3, (5, 5), stride=1, padding=2),\n",
    "            torch.nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# the output should have the same shape as the input\n",
    "assert CycleGenerator()(torch.zeros((30, 3, 32, 32))).shape == torch.Size([30, 3, 32, 32]), \"the output should have the same shape as the input\"\n",
    "assert torch.min(CycleGenerator()(torch.zeros((30, 3, 32, 32)))) > -1, \"outputs should be in the range [-1,1]\"\n",
    "assert torch.max(CycleGenerator()(torch.zeros((30, 3, 32, 32)))) < 1,  \"outputs should be in the range [-1,1]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator\n",
    "\n",
    "The discriminator is similar in concept to what we had in the GAN model: it takes an image and predicts 1 for a real image and 0 for a fake.\n",
    "\n",
    "```\n",
    "- Input: 32x32 pixels, 3 channels.\n",
    "- Three downsampling + convolution blocks:\n",
    "  kernel size = (5, 5), stride = 2, padding = ?,\n",
    "  from 3 -> 64 -> 64 -> 64 channels.\n",
    "- One fully connected layer from (64*4*4) to 1.\n",
    "- Output: 1 output element.\n",
    "```\n",
    "\n",
    "Add batch normalization and ReLU after each convolution, except at the end of the network.\n",
    "\n",
    "**(b) Read through the code below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = torch.nn.Sequential(\n",
    "            # downsampling 32 -> 16 -> 8 -> 4\n",
    "            torch.nn.Conv2d(3, 64, (5, 5), stride=2, padding=2, bias=False),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            torch.nn.Conv2d(64, 64, (5, 5), stride=2, padding=2, bias=False),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            torch.nn.Conv2d(64, 64, (5, 5), stride=2, padding=2, bias=False),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            torch.nn.Flatten(),\n",
    "            \n",
    "            torch.nn.Linear(64 * 4 * 4, 1)\n",
    "        )\n",
    "        # Note: Although this is a binary classifier, we do not apply\n",
    "        #       a sigmoid activation here. We'll optimize a mean-squared\n",
    "        #       error to make the discriminator's task a bit harder and\n",
    "        #       get a slightly better gradient.\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# the output shape should be (30, 1)\n",
    "assert Discriminator()(torch.zeros((30, 3, 32, 32))).shape == torch.Size([30, 1]), \"the output should have shape [30,1]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.11 CycleGAN training loop (2 points)\n",
    "\n",
    "The training loop for the GAN with cycle-consistency loss follows the following procedure:\n",
    "\n",
    "For each batch of samples from domain A and B:\n",
    "* Use the generators to predict the fake B given A, and fake A given B.\n",
    "* Use the generators to reconstruct A given fake B, and B given fake A.\n",
    "\n",
    "The discriminator loss is composed of:\n",
    "* The discriminator losses for real samples from A and B.\n",
    "* The discriminator losses for fake samples from A and B.\n",
    "\n",
    "The cycle-consistency loss is composed of:\n",
    "* The reconstruction loss comparing the real A with the cycled A->B->A.\n",
    "* The reconstruction loss comparing the real B with the cycled B->A->B.\n",
    "\n",
    "Finally, the two groups losses are combined with a weight `lambda_cycle` for the cycle-consistency loss:\n",
    "\n",
    "```loss = discriminator_loss + lambda_cycle * cycle-consistency loss```\n",
    "\n",
    "**(a) Complete the code below to implement this procedure:<span style=\"float:right\"> (2 points)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cycle(generator_ab, generator_ba, discriminator_a, discriminator_b,\n",
    "                data_loader_a, data_loader_b,\n",
    "                epochs=10, lr=0.001, lambda_cycle=0.1, device=device):\n",
    "    mse_loss = torch.nn.MSELoss()\n",
    "    models = torch.nn.ModuleList([generator_ab, generator_ba, discriminator_a, discriminator_b])\n",
    "    optimizer = torch.optim.Adam(models.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    \n",
    "    plt.figure(figsize=(10, 15))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_stats = defaultdict(lambda: 0)\n",
    "        mb_count = 0\n",
    "\n",
    "        disc_a.train()\n",
    "        disc_b.train()\n",
    "        gen_ab.train()\n",
    "        gen_ba.train()\n",
    "\n",
    "        for (real_a, _), (real_b, _) in zip(loader_a, loader_b):\n",
    "            real_a = real_a.to(device)\n",
    "            real_b = real_b.to(device)\n",
    "\n",
    "            # compute fake images A->B->A\n",
    "            fake_ab = generator_ab(real_a)\n",
    "            cycle_aba = generator_ba(fake_ab)\n",
    "\n",
    "            # compute fake images B->A->B\n",
    "            fake_ba = generator_ba(real_b)\n",
    "            cycle_bab = generator_ab(fake_ba)\n",
    "\n",
    "            # run discriminator on real and fake images\n",
    "            d_real_a = discriminator_a(real_a)\n",
    "            # TODO: compute other discriminator output, use gradient reversal where necessary\n",
    "            d_real_b = ...   # TODO\n",
    "            d_fake_ba = ...  # TODO\n",
    "            d_fake_ab = ...  # TODO\n",
    "\n",
    "            # compute discriminator loss\n",
    "            # we optimize the MSE loss function to make the gradients of\n",
    "            # the discriminator a bit easier to use\n",
    "            loss_real_a = mse_loss(d_real_a, torch.ones_like(d_real_a))\n",
    "            loss_real_b = ...  # TODO\n",
    "            loss_fake_a = ...  # TODO\n",
    "            loss_fake_b = ...  # TODO\n",
    "\n",
    "            # compute cycle-consistency loss\n",
    "            loss_cycle_a = mse_loss(cycle_aba, real_a)\n",
    "            loss_cycle_b = mse_loss(cycle_bab, real_b)\n",
    "\n",
    "            # compute loss\n",
    "            loss = loss_real_a + loss_real_b + \\\n",
    "                   loss_fake_a + loss_fake_b + \\\n",
    "                   lambda_cycle * (loss_cycle_a + loss_cycle_b)\n",
    "\n",
    "            # optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # update statistics\n",
    "            epoch_stats['loss'] += loss.item()\n",
    "            epoch_stats['loss_real_a'] += loss_real_a.item()\n",
    "            epoch_stats['loss_real_b'] += loss_real_b.item()\n",
    "            epoch_stats['loss_fake_a'] += loss_fake_a.item()\n",
    "            epoch_stats['loss_fake_b'] += loss_fake_b.item()\n",
    "            epoch_stats['loss_cycle_a'] += loss_cycle_a.item()\n",
    "            epoch_stats['loss_cycle_b'] += loss_cycle_b.item()\n",
    "            mb_count += 1\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            print('Epoch %d: ' % epoch, end='')\n",
    "            for k, v in epoch_stats.items():\n",
    "                print(' %s=%6.4f' % (k, v / mb_count), end='')\n",
    "\n",
    "            images_for_plot = {\n",
    "                'real_a': real_a, 'fake_ab': fake_ab, 'cycle_aba': cycle_aba,\n",
    "                'real_b': real_b, 'fake_ba': fake_ba, 'cycle_bab': cycle_bab,\n",
    "            }\n",
    "\n",
    "            for k in range(10):\n",
    "                for i, (im_title, im) in enumerate(images_for_plot.items()):\n",
    "                    plt.subplot(10, 6, k * 6 + i + 1)\n",
    "                    plt.imshow(im[k].detach().cpu().numpy().transpose(1, 2, 0) / 2 + 0.5)\n",
    "                    if k == 0:\n",
    "                        plt.title(im_title)\n",
    "                    plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.12 Experiment: CycleGAN training (6 points)\n",
    "\n",
    "We can now train our CycleGAN model.\n",
    "\n",
    "**(a) Run the code below and play with the hyperparameters if necessary to learn a reasonable output.**\n",
    "\n",
    "Note that GANs can be notoriously difficult to train, so don't worry if your results are not perfect. Hopefully, you will be able to get somewhat recognizable results, but it's more important that you can interpret and discuss what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_ab = CycleGenerator().to(device)\n",
    "gen_ba = CycleGenerator().to(device)\n",
    "disc_a = Discriminator().to(device)\n",
    "disc_b = Discriminator().to(device)\n",
    "\n",
    "loader_a = torch.utils.data.DataLoader(d_windows, batch_size=32, shuffle=True, num_workers=4)\n",
    "loader_b = torch.utils.data.DataLoader(d_apple, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "train_cycle(gen_ab, gen_ba, disc_a, disc_b, loader_a, loader_b,\n",
    "            epochs=100, lr=0.001, lambda_cycle=1, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Discuss your results and training experience. Was the model easy to train? What do you think of the results? Does it learn a good translation between Windows and Apple emojis?<span style=\"float:right\"> (2 points)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Run some more experiments to study the effect of the `lambda_cycle` weight.<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your experiments here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) What is the effect of the `lambda_cycle` weight? What happens if you set it to a much larger value? What happens if you set it to 0? Can you explain this?<span style=\"float:right\"> (2 points)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e) Why is the reconstructed output (A->B->A or B->A->B) usually better than the translated output (A->B or B->A)?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.13 Final questions (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) Discuss how the balance between the generator and discriminator affects GAN training. What can go wrong if one part is better or learns more quickly than the other?<span style=\"float:right\"> (2 points)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) CycleGAN and similar methods are unsupervised models that learn to map inputs from one domain to another. Does this mapping necessarily preserve the semantics of the images? Why, or why not?<span style=\"float:right\"> (1 point)</span>**\n",
    "<br>(For example, think about how our emoji model would translate flags.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Have a brief look at [CycleGAN, a Master of Steganography](https://arxiv.org/pdf/1712.02950.pdf), a paper published at NIPS 2017. The authors show that a CycleGAN network sometimes 'hides' information in the generated images, to help with the reconstruction. Can you see something like this in your results as well?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The end\n",
    "\n",
    "Well done! Please double check the instructions at the top before you submit your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This assignment has 30 points.*\n",
    "<span style=\"float:right;color:#aaa;font-size:10px;\"> Version 55cc64e / 2024-11-11</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
