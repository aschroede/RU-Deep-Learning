{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning &mdash; Assignment 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fifth assignment for the 2024 Deep Learning course (NWI-IMC070) of the Radboud University."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "**Names:**\n",
    "\n",
    "**Group:**\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions:**\n",
    "* Fill in your names and the name of your group.\n",
    "* Answer the questions and complete the code where necessary.\n",
    "* Keep your answers brief, one or two sentences is usually enough.\n",
    "* Re-run the whole notebook before you submit your work.\n",
    "* Save the notebook as a PDF and submit that in Brightspace together with the `.ipynb` notebook file.\n",
    "* The easiest way to make a PDF of your notebook is via File > Print Preview and then use your browser's print option to print to PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "\n",
    "* The models in this assignment take a while to train. It is faster on a GPU (e.g., on Google Colab), but still doable on a CPU. Plan ahead to leave enough time to analyse your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "In this assignment you will\n",
    "1. Implement an LSTM module from scratch.\n",
    "2. Use the built-in LSTM module from PyTorch.\n",
    "3. Compare fully connected and recurrent neural networks in an experiment.\n",
    "4. Experiment with data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import csv\n",
    "import glob\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.signal\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from IPython import display\n",
    "\n",
    "# fix the seed, so outputs are exactly reproducible\n",
    "torch.manual_seed(12345);\n",
    "\n",
    "# Use the GPU if available\n",
    "def detect_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "device = detect_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Dataset: Atrial fibrillation classification on ECG recordings (1 point)\n",
    "\n",
    "In this assignment we will work with data from the [PhysioNet Computing in Cardiology Challenge 2017](https://physionet.org/content/challenge-2017/1.0.0/) to classify atrial fibrillation in electrocardiograms (ECGs). Atrial fibrillation is an abnormal heart rhythm, which can be recognized as irregular patterns in ECG recordings.\n",
    "\n",
    "**(a) Download the [training dataset](https://physionet.org/files/challenge-2017/1.0.0/training2017.zip) from the challenge website and extract the files.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir -p data\n",
    "# !wget -c -O data/training2017.zip https://physionet.org/files/challenge-2017/1.0.0/training2017.zip\n",
    "# !cd data/ ; unzip -qo training2017.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of a number of recordings and corresponding labels. We use a subset of the dataset that includes only the samples with a normal rhythm (label N or class 0) and those with atrial fibrillation (label A or class 1).\n",
    "\n",
    "**(b) Run the code to load the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGDataset(torch.utils.data.Dataset):\n",
    "    # labels: 'N', 'A', 'O'\n",
    "    def __init__(self, directory, max_length=18286, class_labels=('N', 'A', 'O')):\n",
    "        super().__init__()\n",
    "        self.class_labels = class_labels\n",
    "        self.load_data(directory, max_length)\n",
    "\n",
    "    def load_data(self, directory, max_length):\n",
    "        label_map = {}\n",
    "        with open('%s/REFERENCE.csv' % directory, 'r') as f:\n",
    "            for line in csv.reader(f):\n",
    "                label_map[line[0]] = line[1]\n",
    "\n",
    "        samples = []\n",
    "        lengths = []\n",
    "        labels = []\n",
    "\n",
    "        for file in sorted(glob.glob('%s/*.mat' % directory)):\n",
    "            subject_id = re.match(r'.+(A[0-9]+).mat', file)[1]\n",
    "            label = label_map[subject_id]\n",
    "            if label not in self.class_labels:\n",
    "                # skip this label\n",
    "                continue\n",
    "            mat_data = scipy.io.loadmat(file)\n",
    "            sample = mat_data['val'][0]\n",
    "            if len(sample) < 4000:\n",
    "                # skip short samples\n",
    "                continue\n",
    "            samples.append(np.pad(sample, (0, max_length - len(sample))))\n",
    "            lengths.append(len(sample))\n",
    "            labels.append(self.class_labels.index(label_map[subject_id]))\n",
    "\n",
    "        # concatenate\n",
    "        samples = np.vstack(samples)\n",
    "        lengths = np.stack(lengths)\n",
    "        labels = np.stack(labels)\n",
    "        \n",
    "        # convert to PyTorch tensors\n",
    "        self.samples = torch.tensor(samples, dtype=torch.float32)\n",
    "        self.lengths = torch.tensor(lengths, dtype=torch.long)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    @property\n",
    "    def class_proportions(self):\n",
    "        return torch.mean((torch.arange(len(self.class_labels))[None, :] ==\n",
    "                           self.labels[:, None]).to(torch.float), axis=0)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        l = self.lengths[index]\n",
    "        x = self.samples[index, :l]\n",
    "        y = self.labels[index]\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.samples.shape[0]\n",
    "\n",
    "\n",
    "data = ECGDataset('data/training2017', class_labels=('N', 'A'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recordings have different lengths (between 30 to 60 seconds). There are more \"normal\" recordings than recordings that show atrial fibrillation.\n",
    "\n",
    "**(c) Print some statistics of the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of examples: %d' % len(data))\n",
    "print()\n",
    "print('Minimum length: %d' % torch.min(data.lengths))\n",
    "print('Median length:  %d' % torch.median(data.lengths))\n",
    "print('Maximum length: %d' % torch.max(data.lengths))\n",
    "print()\n",
    "print('Class distribution:', data.class_proportions.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each example has a 1D vector that represents the ECG measurement over time.\n",
    "\n",
    "**(d) Run the code to plot two recordings from each class.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True, figsize=(12, 5))\n",
    "for i, idx in enumerate([0, 3, 1, 4]):\n",
    "    x, y = data[idx]\n",
    "    ax = axes[i // 2][i % 2]\n",
    "    ax.plot(x)\n",
    "    ax.set_title('Label: %s' % data.class_labels[y])\n",
    "    ax.set_xlim(3000, 5000)\n",
    "    ax.set_ylabel('Time (frames)')\n",
    "    ax.set_ylabel('Amplitude (mV)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e) The class distribution in this dataset is quite unbalanced. What consequences could this have?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction\n",
    "\n",
    "To simplify our poblem a bit, we will convert the 1D ECG signals to [spectrograms](https://en.wikipedia.org/wiki/Spectrogram). A spectrogram is a summary of the frequencies in small windows of the recording. These features will make it easier to train a classification model.\n",
    "\n",
    "**(f) Run the code to compute the spectrograms.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGSpectrumDataset(ECGDataset):\n",
    "    NPERSEG = 32\n",
    "    NOVERLAP = 32 // 8\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        # initialize the original dataset to load the samples\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # compute and store the spectrograms to replace the samples\n",
    "        self.compute_spectrum()\n",
    "    \n",
    "    def compute_spectrum(self):\n",
    "        \"\"\"\n",
    "        Replaces the samples in this dataset with spectrograms.\n",
    "        \"\"\"\n",
    "        f, t, Sxx = scipy.signal.spectrogram(self.samples.numpy(), scaling='spectrum',\n",
    "                                             nperseg=self.NPERSEG, noverlap=self.NOVERLAP)\n",
    "        # normalize the measurements for each frequency\n",
    "        Sxx = Sxx - np.mean(Sxx, axis=(0, 2), keepdims=True)\n",
    "        Sxx = Sxx / np.std(Sxx, axis=(0, 2), keepdims=True)\n",
    "        # replace the existing samples in the dataset with the computed spectrograms\n",
    "        self.samples = torch.tensor(Sxx.transpose(0, 2, 1))\n",
    "        # recompute the length of each samples to account for the number of windows\n",
    "        self.lengths = (self.lengths - self.NPERSEG) // (self.NPERSEG - self.NOVERLAP)\n",
    "\n",
    "data_spectrum = ECGSpectrumDataset('data/training2017', class_labels=('N', 'A'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(g) Plot the spectrograms for the four samples from the previous plot.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "for i, idx in enumerate([0, 3, 1, 4]):\n",
    "    x, y = data_spectrum[idx]\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    plt.imshow(x.T)\n",
    "    plt.title('Label: %s' % data.class_labels[y])\n",
    "    # show roughly the same segments as in the previous plot\n",
    "    plt.xlim(3000 // 28, 5000 // 28)\n",
    "    plt.ylabel('Amplitude (mV)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spectrogram data has 17 frequency bins for each window. We will use these as our input features. We normalized the data for each frequency to zero mean, unit variance.\n",
    "\n",
    "**(h) Print the statistics of the spectrum dataset and check the shape of the first sample.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Minimum length: %d' % torch.min(data_spectrum.lengths))\n",
    "print('Median length:  %d' % torch.median(data_spectrum.lengths))\n",
    "print('Maximum length: %d' % torch.max(data_spectrum.lengths))\n",
    "print()\n",
    "print('Mean value:         %f' % torch.mean(data_spectrum.samples))\n",
    "print('Standard deviation: %f' % torch.std(data_spectrum.samples))\n",
    "print()\n",
    "# print the shape of the first sample\n",
    "x, y = data_spectrum[0]\n",
    "print('Shape of first sample:', x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting training and validation sets\n",
    "\n",
    "We will split our dataset in separate training and validation sets (80% &ndash; 20%).\n",
    "\n",
    "**(i) Run the code to create a random split.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = int(0.8 * len(data))\n",
    "val_samples = len(data) - train_samples\n",
    "data_train_original, data_val_original = torch.utils.data.random_split(data_spectrum, (train_samples, val_samples))\n",
    "\n",
    "print('data_train:', len(data_train_original))\n",
    "print('data_val:  ', len(data_val_original))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a balanced dataset by resampling\n",
    "\n",
    "As you have seen, the dataset contains far more normal recordings than recordings with atrial fibrillation. We will create a balanced dataset by including multiple copies of the atrial fibrillation samples.\n",
    "\n",
    "In this assignment we will also use a balanced validation set. This is something you may or may not want to do in practice, because it means that your validation set is no longer representative of the test data. The advantage is that the accuracy on a balanced validation set is easier to compare with the accuracy on the training set.\n",
    "\n",
    "**(j) Run the code to create balanced training and validation sets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset(dataset):\n",
    "    # collect labels from the source dataset\n",
    "    labels = torch.zeros((len(dataset),), dtype=torch.long)\n",
    "    for i, (x, y) in enumerate(dataset):\n",
    "        labels[i] = y\n",
    "    indices = torch.arange(len(dataset), dtype=torch.long)\n",
    "\n",
    "    unique_labels = np.unique(labels.numpy())\n",
    "    \n",
    "    # count the number of samples per class\n",
    "    n = [torch.sum((labels == label).to(torch.long)).item()\n",
    "         for label in unique_labels]\n",
    "    \n",
    "    # perhaps the dataset is already balanced?\n",
    "    if len(np.unique(n)) == 1:\n",
    "        return dataset\n",
    "    \n",
    "    print('Samples per class:', n)\n",
    "    for i, label in enumerate(unique_labels):\n",
    "        # we will add more samples unless every class has the same number of samples\n",
    "        while n[i] < max(n):\n",
    "            extra_samples = max(n) - n[i]\n",
    "            print('- Repeating %d samples for class %d' % (extra_samples, label))\n",
    "\n",
    "            # take a random subset of samples from this class\n",
    "            idxs = torch.where(labels == label)[0]\n",
    "            idxs = idxs[torch.randperm(idxs.shape[0])]\n",
    "            idxs = idxs[:extra_samples]\n",
    "\n",
    "            # add these indices to the list\n",
    "            indices = torch.cat((indices, idxs))\n",
    "            n[i] += len(idxs)\n",
    "    \n",
    "    # return the subset as a new torch dataset\n",
    "    return torch.utils.data.Subset(dataset, indices)\n",
    "\n",
    "print('Balancing the training set')\n",
    "data_train = balance_dataset(data_train_original)\n",
    "print('Balancing the validation set')\n",
    "data_val   = balance_dataset(data_val_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting recordings into chunks\n",
    "\n",
    "The recordings in our dataset all have different lengths and are generally quite long. To simplify training, we will split them into smaller chunks of 40 time steps each. This means that each recording will have multiple chunks in the dataset.\n",
    "\n",
    "**(k) Run the code to create the pre-chunked dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChunkedDataset(torch.utils.data.TensorDataset):\n",
    "    def __init__(self, source_dataset, chunk_size=40):\n",
    "        super().__init__()\n",
    "        self.make_chunks(source_dataset, chunk_size)\n",
    "    \n",
    "    def make_chunks(self, source_dataset, chunk_size):\n",
    "        all_x, all_y = [], []\n",
    "        for x, y in source_dataset:\n",
    "            for chunk in range(x.shape[0] // chunk_size):\n",
    "                offset = chunk * chunk_size\n",
    "                all_x.append(x[offset:offset + chunk_size])\n",
    "                all_y.append(y)\n",
    "        self.tensors = (torch.stack(all_x), torch.tensor(all_y))\n",
    "\n",
    "chunked_data_train = ChunkedDataset(data_train_original)\n",
    "chunked_data_val = ChunkedDataset(data_val_original)\n",
    "\n",
    "# rebalance to compensate for any differences in length\n",
    "chunked_data_train = balance_dataset(chunked_data_train)\n",
    "chunked_data_val   = balance_dataset(chunked_data_val)\n",
    "\n",
    "print('chunked_data_train:', len(chunked_data_train))\n",
    "print('chunked_data_val:  ', len(chunked_data_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data loaders\n",
    "\n",
    "As in the previous assignments, we will use the PyTorch [DataLoader](https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader) class to divide our datasets in minibatches.\n",
    "\n",
    "**(l) Run the code to create the data loaders. Look at the shape of the first minibatch.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 192\n",
    "chunked_loaders = {\n",
    "    'train': torch.utils.data.DataLoader(chunked_data_train, shuffle=True, batch_size=batch_size),\n",
    "    'val':   torch.utils.data.DataLoader(chunked_data_val, batch_size=batch_size),\n",
    "}\n",
    "\n",
    "# print the x and y shapes for one minibatch\n",
    "for x, y in chunked_loaders['train']:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Implementing an LSTM (5 points)\n",
    "\n",
    "Time series data such as the ECG recordings are a good target for recurrent neural network.\n",
    "\n",
    "The class below implements an RNN layer in PyTorch, using the equations discussed in the lecture. See also\n",
    "[section 9.4.2](http://d2l.ai/chapter_recurrent-neural-networks/rnn.html#recurrent-networks-with-hidden-states) of the Dive into Deep Learning book.\n",
    "\n",
    "**(a) Read through the code to see how the RNN works.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A simple recurrent neural network layer.\n",
    "\n",
    "    Parameters:\n",
    "       num_inputs:  scalar, the number of inputs to this module\n",
    "       num_hiddens: scalar, the number of hidden units\n",
    "    \n",
    "    Input and output: see the forward function.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_inputs, num_hiddens):\n",
    "        super().__init__()\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.initialize_parameters()\n",
    "\n",
    "    def initialize_parameters(self):\n",
    "        \"\"\"\n",
    "        Initializes the parameters of the RNN module.\n",
    "        \n",
    "        This initializes the bias vector b_h and weight matrices W_xh and W_hh.\n",
    "        \"\"\"\n",
    "        # Helper function that constructs two weight matrices and a bias vector\n",
    "        def triple():\n",
    "            return (torch.nn.Parameter(torch.normal(0, 0.01, size=(self.num_inputs, self.num_hiddens))),\n",
    "                    torch.nn.Parameter(torch.normal(0, 0.01, size=(self.num_hiddens, self.num_hiddens))),\n",
    "                    torch.nn.Parameter(torch.zeros(size=(self.num_hiddens,))))\n",
    "\n",
    "        # parameters for the rnn\n",
    "        self.W_xh, self.W_hh, self.b_h = triple()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Computes the forward pass of the RNN module.\n",
    "        \n",
    "        Input:\n",
    "           inputs:  a tensor of shape (samples, steps, input features)\n",
    "                    giving the input for each sample at each step\n",
    "        \n",
    "        Output:\n",
    "           outputs: a tensor of shape (samples, steps, hidden features)\n",
    "                    providing the hidden values at the end of each step\n",
    "           state:   a tuple (hiddens,)\n",
    "                    the state of the RNN at the end of the last step,\n",
    "                    with hiddens a tensor of shape (samples, hidden_features)\n",
    "        \"\"\"\n",
    "        batch_size = inputs.shape[0]\n",
    "\n",
    "        # initialize state\n",
    "        state = (torch.zeros(size=(batch_size, self.num_hiddens),\n",
    "                             dtype=inputs.dtype, device=inputs.device),)\n",
    "\n",
    "        # run steps\n",
    "        outputs = []\n",
    "        for step in range(inputs.shape[1]):\n",
    "            state = self.one_step(inputs[:, step], state)\n",
    "            outputs.append(state[0])\n",
    "\n",
    "        # concatenate outputs\n",
    "        outputs = torch.stack(outputs, axis=1)\n",
    "        return outputs, state\n",
    "\n",
    "    def one_step(self, x, state):\n",
    "        \"\"\"\n",
    "        Run a single step of the RNN module.\n",
    "        \n",
    "        Input:\n",
    "           x:     a tensor of shape (samples, input features)\n",
    "                  giving the input for each sample at the current step\n",
    "           state: a tuple (hiddens,)\n",
    "                  the state of the RNN at the end of the previous step,\n",
    "                  with hiddens a tensor of shape (samples, hidden_features)\n",
    "        \"\"\"\n",
    "        # extract current state\n",
    "        (h,) = state\n",
    "\n",
    "        # new hidden state\n",
    "        h = torch.tanh(x @ self.W_xh + h @ self.W_hh + self.b_h)\n",
    "\n",
    "        # return the state\n",
    "        return (h,)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return ('RNN(num_inputs=%d, num_hiddens=%d)' %\n",
    "                (self.num_inputs, self.num_hiddens))\n",
    "\n",
    "\n",
    "# quick sanity check\n",
    "rnn = RNN(3, 5)\n",
    "print(rnn)\n",
    "print('Parameters:')\n",
    "for name, param in rnn.named_parameters():\n",
    "    print(' - %s:' % name, tuple(param.shape))\n",
    "\n",
    "assert rnn(torch.randn(2,10,3))[0].shape == torch.Size([2, 10, 5]), \"The shape of the output is incorrect\"\n",
    "assert len(rnn(torch.randn(2,10,3))[1]) == 1, \"The hidden state should have 1 element\"\n",
    "assert rnn(torch.randn(2,10,3))[1][0].shape == torch.Size([2, 5]), \"The shape of the state is incorrect\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The design of the LSTM module is more complex than that of the RNN, but it follows a similar pattern of looping over all steps in the input. You can use the RNN implementation as a basis for an LSTM module.\n",
    "\n",
    "**(b) Implement the LSTM module below.<span style=\"float:right\"> (5 points)</span>**\n",
    "\n",
    "The equations and code on the slides, or in [d2l 10.1](http://d2l.ai/chapter_recurrent-modern/lstm.html) can provide some inspiration. Be aware that the d2l book uses `(steps, samples, ...)` instead of `(samples, steps, ...)` as the shapes for the input and output variables, so you probably cannot copy code directly. Use the RNN implementation above and adapt this to the LSTM equations from the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(torch.nn.Module):\n",
    "    def __init__(self, num_inputs, num_hiddens):\n",
    "        super().__init__()\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.initialize_parameters()\n",
    "\n",
    "    def initialize_parameters(self):\n",
    "        # TODO initialize the LSTM weights\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # TODO implement the forward pass of the LSTM\n",
    "\n",
    "    def __repr__(self):\n",
    "        return ('LSTM(num_inputs=%d, num_hiddens=%d)' %\n",
    "                (self.num_inputs, self.num_hiddens))\n",
    "\n",
    "\n",
    "# quick sanity check\n",
    "lstm = LSTM(3, 5)\n",
    "print(lstm)\n",
    "for name, param in lstm.named_parameters():\n",
    "    print(' - %s:' % name, tuple(param.shape))\n",
    "\n",
    "assert len(list(lstm.parameters())) == 12, \"There should be 12 parameters in an LSTM layer\"\n",
    "assert len(lstm(torch.randn(2,10,3))) == 2, \"LSTM should return a tuple (output, state)\"\n",
    "assert len(lstm(torch.randn(2,10,3))[1]) == 2, \"The hidden state should have 2 elements, h and c\"\n",
    "assert lstm(torch.randn(2,10,3))[1][0].shape == torch.Size([2, 5]), \"The shape of the hidden state is incorrect\"\n",
    "assert lstm(torch.randn(2,10,3))[1][1].shape == torch.Size([2, 5]), \"The shape of the hidden state is incorrect\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Defining the training loop\n",
    "\n",
    "As last week, we need to define some functions to run the train the models.\n",
    "\n",
    "The code is essentially the same as in assignment 4.\n",
    "\n",
    "**(a) Run the code to define the functions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred_y, true_y):\n",
    "    # Computes the mean accuracy.\n",
    "    if pred_y.shape[1] == 1:\n",
    "        # binary classification\n",
    "        correct = (pred_y[:, 0] > 0).to(true_y.dtype) == true_y\n",
    "    else:\n",
    "        # multi-class classification\n",
    "        correct = pred_y.argmax(dim=1) == true_y\n",
    "    return int(correct.sum()) / len(true_y)\n",
    "\n",
    "class Metrics:\n",
    "    \"\"\"Accumulate mean values of one or more metrics.\"\"\"\n",
    "    def __init__(self, n):\n",
    "        self.count = 0\n",
    "        self.sum = (0,) * n\n",
    "    def add(self, count, *values):\n",
    "        self.count += count\n",
    "        self.sum = tuple(s + count * v for s,v in zip(self.sum,values))\n",
    "    def mean(self):\n",
    "        return tuple(s / self.count for s in self.sum)\n",
    "\n",
    "def evaluate(net, test_loader, loss_function=torch.nn.CrossEntropyLoss(), device=device):\n",
    "    \"\"\"\n",
    "    Evaluate a model on the given dataset.\n",
    "    Return loss, accuracy\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        metrics = Metrics(2)\n",
    "        for x, y in test_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            pred_y = net(x)\n",
    "            loss = loss_function(pred_y, y)\n",
    "            acc = accuracy(pred_y, y)\n",
    "            metrics.add(len(y), loss.item(), acc)\n",
    "        return metrics.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plotter:\n",
    "    \"\"\"For plotting data in animation.\"\"\"\n",
    "    # Based on d2l.Animator\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear',\n",
    "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "                 figsize=(3.5, 2.5)):\n",
    "        \"\"\"Defined in :numref:`sec_utils`\"\"\"\n",
    "        # Incrementally plot multiple lines\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "        self.fig, self.axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes, ]\n",
    "        # Use a function to capture arguments\n",
    "        def config_axes():\n",
    "            axis = self.axes[0]\n",
    "            axis.set_xlabel(xlabel), axis.set_ylabel(ylabel)\n",
    "            axis.set_xscale(xscale), axis.set_yscale(yscale)\n",
    "            axis.set_xlim(xlim),     axis.set_ylim(ylim)\n",
    "            if legend:\n",
    "                axis.legend(legend)\n",
    "            axis.grid()\n",
    "        self.config_axes = config_axes\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "\n",
    "    def add(self, x, y):\n",
    "        # Add multiple data points into the figure\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        display.display(self.fig)\n",
    "        display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, data_loaders, num_epochs, lr=0.001, optimizer=torch.optim.Adam, device=device):\n",
    "    \"\"\"\n",
    "    Train a network on the given data set.\n",
    "    After every epoch compute validation loss and accuracy.\n",
    "    \"\"\"\n",
    "    net.to(device)\n",
    "    train_loader = data_loaders['train']\n",
    "    num_batches = len(train_loader)\n",
    "    optimizer = optimizer(net.parameters(), lr=lr)\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    plotter = Plotter(xlabel='epoch', xlim=[1, num_epochs],\n",
    "                      legend=['train loss', 'train acc', 'val loss', 'val acc'])\n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        # Sum of training loss, sum of training accuracy, no. of examples\n",
    "        net.train()\n",
    "        metrics = Metrics(2)\n",
    "        for i, (x, y) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            pred_y = net(x)\n",
    "            loss = loss_function(pred_y, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                acc = accuracy(pred_y, y)\n",
    "                metrics.add(len(y), loss.item(), acc)\n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                train_loss, train_acc = metrics.mean()\n",
    "                plotter.add(epoch + (i + 1) / num_batches, (train_loss, train_acc, None, None))\n",
    "        val_loss, val_acc = evaluate(net, data_loaders['val'], loss_function=loss_function, device=device)\n",
    "        plotter.add(epoch + 1, (None, None, val_loss, val_acc))\n",
    "    train_loss, train_acc = metrics.mean()\n",
    "    train_time = time.time() - start_time\n",
    "    print(f'train loss {train_loss:.3f}, train acc {train_acc:.3f}, '\n",
    "          f'val loss {val_loss:.3f}, val acc {val_acc:.3f}')\n",
    "    print(f'{metrics.count * num_epochs / train_time:.1f} examples/sec '\n",
    "          f'on {str(device)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Constructing some networks (5 points)\n",
    "\n",
    "In the next experiments you will train different network architectures to see how they perform on the ECG dataset.\n",
    "\n",
    "The input to all networks has the shape (samples, time steps, features) = (mb_size, 40, 17). The output should be a two features, shape (mb_size, 2), that will be used in a cross-entropy loss function. (The networks should not include the final softmax activation function.)\n",
    "\n",
    "Some simple baselines:\n",
    "* `FullyConnectedNet`: A simple fully connected network that takes all features.\n",
    "* `MeanSpectrumNet`: A fully connected network that works on the mean spectrum over all time steps.\n",
    "\n",
    "A convolutional network:\n",
    "* `ConvNet`: This network does a convolution over the time steps, using the 17 input features as channels.\n",
    "\n",
    "Some recurrent models:\n",
    "* `RNNNet`: A recurrent network with a simple RNN module.\n",
    "* `LSTMNet`: A recurrent network with a more advanced LSTM module.\n",
    "* `TorchLSTMNet`: The same model, but using the PyTorch implementation of the LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FullyConnectedNet\n",
    "\n",
    "**(a) Check the implementation of the following baseline architecture:**\n",
    "\n",
    "* Linear layer: network inputs to 512 units followed by a ReLU.\n",
    "* Linear layer: 512 to 256 units followed by a ReLU.\n",
    "* Linear layer: 256 to the network output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedNet(torch.nn.Module):\n",
    "    def __init__(self, inputs, outputs=2):\n",
    "        super().__init__()\n",
    "\n",
    "        # by defining these layers here, they are included in the\n",
    "        # parameters() list of this module, so they can be trained\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(inputs, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, outputs)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (samples, steps, inputs)\n",
    "        return self.net(x)\n",
    "\n",
    "net = FullyConnectedNet(40 * 17)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MeanSpectrumNet\n",
    "\n",
    "**(b) Check the implementation of the following baseline architecture:**\n",
    "\n",
    "* Compute the mean spectrum (mean over the steps dimension).\n",
    "* Linear layer: network inputs to 128 units followed by a ReLU.\n",
    "* Linear layer: 128 to 64 units followed by a ReLU.\n",
    "* Linear layer: 64 to the network output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanSpectrumNet(torch.nn.Module):\n",
    "    def __init__(self, inputs=17, outputs=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(inputs, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, outputs),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (samples, steps, inputs)\n",
    "        # compute the mean over all steps\n",
    "        x = torch.mean(x, axis=1)\n",
    "        return self.net(x)\n",
    "\n",
    "net = MeanSpectrumNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConvNet\n",
    "\n",
    "**(c) Complete the implementation of the following architecture:<span style=\"float:right\"> (1 point)</span>**\n",
    "\n",
    "Convolution over the steps, using frequencies as channels:\n",
    "* 1D-convolution: network inputs to 32 channels, kernel size 3, ReLU.\n",
    "* Average pooling: 2.\n",
    "* 1D-convolution: 32 to 64 channels, kernel size 3, ReLU.\n",
    "* Average pooling: 2.\n",
    "* 1D-convolution: 64 to 128 channels, kernel size 3, ReLU.\n",
    "* `AdaptiveAvgPool1d(1)`: Compute the mean for each channel over all steps.\n",
    "* Flatten.\n",
    "* Linear layer: 128 to the network output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(torch.nn.Module):\n",
    "    def __init__(self, inputs=1, outputs=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = torch.nn.Sequential(\n",
    "            # TODO add the convolutional and pooling layers\n",
    "            \n",
    "            torch.nn.AdaptiveAvgPool1d(1),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(128, outputs),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (samples, steps, inputs)\n",
    "        # swap the steps and inputs dimensions, so we can convolve over\n",
    "        # the steps use the frequencies as channels\n",
    "        x = x.transpose(2, 1)\n",
    "        return self.net(x)\n",
    "\n",
    "net = ConvNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNNNet\n",
    "\n",
    "**(d) Check the implementation of the following architecture:**\n",
    "\n",
    "* RNN: network input to 128 hidden units.\n",
    "* Use the final hidden state from the RNN.\n",
    "* Linear layer: 128 to 128 units followed by a ReLU.\n",
    "* Linear layer: 128 to the network output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNNet(torch.nn.Module):\n",
    "    def __init__(self, inputs=17, outputs=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rnn = RNN(inputs, 128)\n",
    "        self.linear = torch.nn.Sequential(\n",
    "            torch.nn.Linear(128, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, outputs)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (samples, steps, inputs)\n",
    "        out, (h,) = self.rnn(x)\n",
    "        \n",
    "        # use the final RNN hidden state as input\n",
    "        # for the fully connected part\n",
    "        return self.linear(h)\n",
    "\n",
    "net = RNNNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTMNet\n",
    "\n",
    "**(e) Implement the following architecture: (see RNNNet for an example)<span style=\"float:right\"> (2 points)</span>**\n",
    "\n",
    "* LSTM: network input to 128 hidden units.\n",
    "* Use the final hidden state from the LSTM.\n",
    "* Linear layer: 128 to 128 units followed by a ReLU.\n",
    "* Linear layer: 128 to the network output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMNet(torch.nn.Module):\n",
    "    def __init__(self, inputs=17, outputs=2):\n",
    "        super().__init__()\n",
    "\n",
    "        # TODO define the LSTM layer and the linear network\n",
    "        #      (see RNNNet for an example)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (samples, steps, inputs)\n",
    "        # TODO call the LSTM layer and then the linear network\n",
    "        #      (see RNNNet for an example)\n",
    "\n",
    "net = LSTMNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TorchLSTMNet\n",
    "\n",
    "Implementing your own modules can be fun and good learning experience, but it is not always the most efficient solution. The built-in [LSTM implementation](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM) from PyTorch is much faster than our own version.\n",
    "\n",
    "**(f) Implement a network similar to LSTMNet using the PyTorch torch.nn.LSTM module.<span style=\"float:right\"> (2 points)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchLSTMNet(torch.nn.Module):\n",
    "    # TODO make this identical to LSTMNet, but use torch.nn.LSTM\n",
    "    #      instead of the LSTM layer you implemented yourself\n",
    "\n",
    "net = TorchLSTMNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Experiments\n",
    "\n",
    "**(a) Train the models on the chunked dataset.**\n",
    "\n",
    "You may change the parameters as you see fit, but document the changes you make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(MeanSpectrumNet(), chunked_loaders, num_epochs=100, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(FullyConnectedNet(40 * 17), chunked_loaders, num_epochs=25, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(ConvNet(17), chunked_loaders, num_epochs=50, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(RNNNet(17), chunked_loaders, num_epochs=50, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(LSTMNet(17), chunked_loaders, num_epochs=25, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(TorchLSTMNet(17), chunked_loaders, num_epochs=25, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Discussion (11 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) Briefly discuss and compare the performance of the models in your experiments. Which worked best and why?<span style=\"float:right\"> (2 points)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here.\n",
    "\n",
    "* *MeanSpectrumNet*:\n",
    "* *FullyConnectedNet*:\n",
    "* *ConvNet*:\n",
    "* *RNNNet*:\n",
    "* *(Torch)LSTMNet*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Why do some of those models generalize better than others?<span style=\"float:right\"> (2 points)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) How does your LSTM implementation compare with the PyTorch implementation?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) Your RNN model probably didn't work well. Why is that model more difficult to train than the LSTM?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e) The convolutional network and the LSTM in these experiments both work on the time dimension. What is an advantage of the convolutional network over the LSTM?<span style=\"float:right\"> (1 points)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(f) What is an advantage of the LSTM over a convolutional network?<span style=\"float:right\"> (1 points)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(g) For reasons of speed, we used a fairly small window of 40 time steps. Suppose that we would make this window much larger. How do you think this would affect each model?<span style=\"float:right\"> (2 points)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(h) One of the difficulties with recurrent networks is that inputs from early steps are quite far away from the final result. How would you suggest to reduce that problem?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7 Data augmentation\n",
    "\n",
    "Especially if your dataset is small, data augmentation can help to improve the performance of your network.\n",
    "\n",
    "We have an easy way to add some data augmentation to the ECG dataset. In our preprocessing, we divided each recording into small chunks of 40 time steps, which we then reused in every epoch. We can add more variation to the training set by creating chunks at random positions.\n",
    "\n",
    "The [DataLoader](https://pytorch.org/docs/stable/data.html) class in PyTorch has a `collate_fn` parameter to which we can pass a function. This function is called for each minibatch in each epoch. We will use this to extract a random chunk from each sample.\n",
    "\n",
    "The function `random_chunk_collate_fn` takes a minibatch of samples, chooses a random offset for each sample, extracts a small chunk at that position, and then concatenates and returns the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_chunk_collate_fn(samples, window_size):\n",
    "    # Take a list of tensors of (steps_i, features),\n",
    "    # extract a random window of length window_size from each tensor,\n",
    "    # concatenate to a tensor of shape (samples, window_size, features).\n",
    "    x_batch = torch.empty((len(samples), window_size) + samples[0][0].shape[1:],\n",
    "                          device=samples[0][0].device, dtype=samples[0][0].dtype)\n",
    "    y_batch = torch.empty((len(samples),),\n",
    "                          device=samples[0][1].device, dtype=samples[0][1].dtype)\n",
    "    for i, (x, y) in enumerate(samples):\n",
    "        # extract a random window\n",
    "        offset = torch.randint(x.shape[0] - window_size, (1,))\n",
    "        x_batch[i, :] = x[offset:offset + window_size]\n",
    "        y_batch[i] = y\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We construct a new DataLoader for our training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test to see the x and y shapes for one sample\n",
    "random_chunk_loaders = {\n",
    "    'train': torch.utils.data.DataLoader(data_train, shuffle=True, batch_size=batch_size,\n",
    "                                         collate_fn=lambda s: random_chunk_collate_fn(s, window_size=40)),\n",
    "    'val':   chunked_loaders['val']\n",
    "}\n",
    "for (x, y) in random_chunk_loaders['train']:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the pre-chunked dataset was much larger than the new dataset with on-the-fly chunking. You might want to increase the number of training epochs a bit to make sure that the network sees a similar number of examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Minibatches in chunked_loader[\\'train\\']:      ', len(chunked_loaders['train']))\n",
    "print('Minibatches in random_chunk_loaders[\\'train\\']:', len(random_chunk_loaders['train']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how this data augmentation method affects the performance of your networks.\n",
    "\n",
    "**(a) Train the MeanSpectrumNet, FullyConnectedNet, ConvNet and TorchLSTMNet from the previous experiments on data from the `random_chunk_loaders`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(MeanSpectrumNet(), random_chunk_loaders, num_epochs=100, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(FullyConnectedNet(40 * 17), random_chunk_loaders, num_epochs=100, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(ConvNet(17), random_chunk_loaders, num_epochs=100, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(TorchLSTMNet(17), random_chunk_loaders, num_epochs=100, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.8 Discussion (9 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) How does the data augmentation influence the training and validation results? Can you explain this?<span style=\"float:right\"> (2 points)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Why does the data augmentation affect some models more than others?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Should we also do data augmentation on the validation set? Why, or why not?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) Data augmentation is often a good way to add some domain knowledge to your model. Based on your knowledge of ECGs, why is (or isn't) our augmentation method a good idea?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e) Give an example of another suitable augmentation method and explain why it would work for this data.<span style=\"float:right\"> (2 points)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(f) Give an example of an augmentation method that might be suitable for other data but would probably not work here. Explain why.<span style=\"float:right\"> (2 points)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The end\n",
    "\n",
    "Well done! Please double check the instructions at the top before you submit your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This assignment has 31 points.*\n",
    "<span style=\"float:right;color:#aaa;font-size:10px;\"> Version 231feba / 2024-10-03</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}